##ğŸ§­ Smart GIKI Navigator â€“ Vision & Voice Guided Campus Mapping  
##ğŸ¯ A Location-Aware Navigation Demo Without GPS â€“ Built with MobileNetV2, Speech Recognition & Google Maps API  
## License: MIT â€¢ Python â€¢ Streamlit â€¢ TorchVision â€¢ gTTS â€¢ Google Maps API  

##ğŸ¥ Your camera becomes your compass.  
##ğŸ§  This AI-powered app locates you using a photo, takes your voice as destination input, and gives real-time walking directions â€” all without relying on GPS.  

---

## ğŸ’¡ Project Overview & Motivation  

How do you navigate when GPS isnâ€™t available, like deep inside campuses or buildings?  
**Smart GIKI Navigator** tackles that â€” an AI-based demo designed to visually recognize where you are and guide you to where you need to go.

Built as a final project for our CV/NLP course, this system uses:
- **Image-based classification** to detect your location from a photo  
- **Voice commands** to understand your destination  
- **Google Maps API** to provide step-by-step walking directions  
- **Text-to-speech** to speak each navigation step aloud

It's a smart, voice-guided assistant â€” optimized for GIKI, but adaptable anywhere.

---

## âœ¨ Key Features  

ğŸ” **Visual Location Detection**  
Upload an image â†’ model predicts which building you're at using MobileNetV2.

ğŸ™ï¸ **Voice Navigation**  
Say â€œtake me to the libraryâ€ â†’ model extracts your intended destination.

ğŸ—ºï¸ **Google Maps Step-by-Step Directions**  
Gets real walking directions using coordinates + Google Maps API.

ğŸ”Š **Audio Instructions**  
Each step is spoken aloud using gTTS for intuitive guidance.

ğŸ–¥ï¸ **Streamlit Web App**  
Everything is wrapped in a clean, interactive UI â€” no coding needed.

---

## ğŸš€ How It Works

1. Upload an image â†’ model predicts location & coordinates  
2. Speak or type your destination â†’ voice model extracts the location  
3. System queries Google Maps API â†’ returns walking instructions  
4. Directions are printed + spoken using generated audio  
5. Youâ€™re guided â€” visually and aurally!

---

## ğŸ“ Project Structure

Smart-GIKI-Navigator/
â”œâ”€â”€ app-base.py # Streamlit app (main interface)
â”œâ”€â”€ train_classifier.py # Trains MobileNetV2 location classifier
â”œâ”€â”€ .env # Stores your Google Maps API key (not public)
â”œâ”€â”€ static/
â”‚ â””â”€â”€ audio/ # Stores generated voice files
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ CV_utils.py # Image classification (MobileNetV2 + GIKI landmarks)
â”‚ â”œâ”€â”€ voice_utils.py # Voice input & gTTS text-to-speech
â”‚ â””â”€â”€ map_utils.py # Google Maps API integration
â”œâ”€â”€ models/
â”‚ â””â”€â”€ building_classifier.pth # Saved PyTorch model weights
â”œâ”€â”€ requirements.txt # Project dependencies
â”œâ”€â”€ LICENSE # MIT License
â””â”€â”€ README.md # You're reading it

yaml
Copy
Edit

---

## ğŸ”’ API Keys & Model Notes  

- **Google Maps API**  
  Add your API key to a `.env` file like this:  
GOOGLE_MAPS_API_KEY=YOUR_API_KEY_HERE

yaml
Copy
Edit
Never commit your `.env` file to GitHub.

- **Image Classifier Model**  
The model (`building_classifier.pth`) classifies photos into one of GIKIâ€™s key buildings (e.g., FCSE, FME, Library).  
You can retrain using your own dataset via `train_classifier.py`.

---

## ğŸ› ï¸ Setup and Installation  

### 1. Clone the Repository  
```bash
git clone https://github.com/yourusername/Smart-GIKI-Navigator.git
cd Smart-GIKI-Navigator
2. Create Virtual Environment (Recommended)
bash
Copy
Edit
python -m venv venv
# Activate:
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
3. Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
4. Add Your Google Maps API Key
Create a file .env in the root folder with this line:

ini
Copy
Edit
GOOGLE_MAPS_API_KEY=YOUR_API_KEY_HERE
5. Run the App
bash
Copy
Edit
streamlit run app-base.py
ğŸ§ª Train Your Own Model
To retrain the location classifier:

Organize building photos into class-labeled folders under a dataset directory

Update the DATA_DIR path in train_classifier.py accordingly

Run:

bash
Copy
Edit
python train_classifier.py
Your new weights will be saved to models/building_classifier.pth

ğŸ™‹â€â™‚ï¸ Contributing
Contributions welcome!
Fork the repo â†’ make a branch â†’ submit a PR!

ğŸ“œ License
This project is licensed under the MIT License.
Feel free to reuse or adapt â€” just give credit where due.

ğŸ‘¥ Credits
Developed by Aaiz Mohsin (BS AI, GIKI) as part of the CV & NLP course project (Semester 6)
Grateful to our instructors and GIKI for their guidance.

ğŸ¤ Letâ€™s Connect
ğŸ’¬ Feedback, improvements, or collaboration ideas?
ğŸ“« Aaiz-Am17 on GitHub
ğŸŒ Drop a â­ if you found this helpful!
